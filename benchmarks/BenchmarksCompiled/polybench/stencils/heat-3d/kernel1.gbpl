type _SIZE_T_TYPE = bv32;

procedure _ATOMIC_OP64(x : [bv32]bv64, y : bv32) returns (z : bv64, A : [bv32]bv64);
var {:source_name "A"} {:global} $$A : [bv32]bv64;
axiom {:array_info "$$A"} {:global} {:elem_width 64} {:source_name "A"} {:source_elem_width 64} {:source_dimensions "*"} true;
var {:race_checking} {:global} {:elem_width 64} {:source_elem_width 64} {:source_dimensions "*"} _READ_HAS_OCCURRED_$$A : bool;
var {:race_checking} {:global} {:elem_width 64} {:source_elem_width 64} {:source_dimensions "*"} _WRITE_HAS_OCCURRED_$$A : bool;
var {:race_checking} {:global} {:elem_width 64} {:source_elem_width 64} {:source_dimensions "*"} _ATOMIC_HAS_OCCURRED_$$A : bool;

var {:source_name "B"} {:global} $$B : [bv32]bv64;
axiom {:array_info "$$B"} {:global} {:elem_width 64} {:source_name "B"} {:source_elem_width 64} {:source_dimensions "*"} true;
var {:race_checking} {:global} {:elem_width 64} {:source_elem_width 64} {:source_dimensions "*"} _READ_HAS_OCCURRED_$$B : bool;
var {:race_checking} {:global} {:elem_width 64} {:source_elem_width 64} {:source_dimensions "*"} _WRITE_HAS_OCCURRED_$$B : bool;
var {:race_checking} {:global} {:elem_width 64} {:source_elem_width 64} {:source_dimensions "*"} _ATOMIC_HAS_OCCURRED_$$B : bool;

const _WATCHED_OFFSET : bv32;
const {:global_offset_x} global_offset_x : bv32;
const {:global_offset_y} global_offset_y : bv32;
const {:global_offset_z} global_offset_z : bv32;
const {:group_id_x} group_id_x : bv32;
const {:group_id_y} group_id_y : bv32;
const {:group_size_x} group_size_x : bv32;
const {:group_size_y} group_size_y : bv32;
const {:group_size_z} group_size_z : bv32;
const {:local_id_x} local_id_x : bv32;
const {:local_id_y} local_id_y : bv32;
const {:local_id_z} local_id_z : bv32;
const {:num_groups_x} num_groups_x : bv32;
const {:num_groups_y} num_groups_y : bv32;
const {:num_groups_z} num_groups_z : bv32;
function FADD64(bv64, bv64) : bv64;
function FMUL64(bv64, bv64) : bv64;
function {:bvbuiltin "bvadd"} BV32_ADD(bv32, bv32) : bv32;
function {:bvbuiltin "bvadd"} BV64_ADD(bv64, bv64) : bv64;
function {:bvbuiltin "bvand"} BV32_AND(bv32, bv32) : bv32;
function {:bvbuiltin "bvmul"} BV32_MUL(bv32, bv32) : bv32;
function {:bvbuiltin "bvmul"} BV64_MUL(bv64, bv64) : bv64;
function {:bvbuiltin "bvor"} BV32_OR(bv32, bv32) : bv32;
function {:bvbuiltin "bvsdiv"} BV64_SDIV(bv64, bv64) : bv64;
function {:bvbuiltin "bvsge"} BV32_SGE(bv32, bv32) : bool;
function {:bvbuiltin "bvsge"} BV64_SGE(bv64, bv64) : bool;
function {:bvbuiltin "bvsgt"} BV64_SGT(bv64, bv64) : bool;
function {:bvbuiltin "bvsle"} BV32_SLE(bv32, bv32) : bool;
function {:bvbuiltin "bvsle"} BV64_SLE(bv64, bv64) : bool;
function {:bvbuiltin "bvslt"} BV64_SLT(bv64, bv64) : bool;
function {:bvbuiltin "bvsrem"} BV64_SREM(bv64, bv64) : bv64;
function {:bvbuiltin "bvsub"} BV32_SUB(bv32, bv32) : bv32;
function {:bvbuiltin "bvsub"} BV64_SUB(bv64, bv64) : bv64;
function {:bvbuiltin "bvudiv"} BV32_UDIV(bv32, bv32) : bv32;
function {:bvbuiltin "bvuge"} BV32_UGE(bv32, bv32) : bool;
function {:bvbuiltin "bvule"} BV32_ULE(bv32, bv32) : bool;
function {:bvbuiltin "bvurem"} BV32_UREM(bv32, bv32) : bv32;
function {:bvbuiltin "sign_extend 32"} BV32_SEXT64(bv32) : bv64;
function {:bvbuiltin "zero_extend 31"} BV1_ZEXT32(bv1) : bv32;
function {:bvbuiltin "zero_extend 32"} BV32_ZEXT64(bv32) : bv64;
procedure {:source_name "kernel1"} {:kernel} $kernel1($n:bv32, $c0:bv64)
requires {:sourceloc_num 0} (if $n == 512bv32 then 1bv1 else 0bv1) != 0bv1;
requires {:sourceloc_num 1} (if BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_SGE($n, 3bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_SLE($n, 2147483647bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE($c0, 1bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE($c0, 500bv64) then 1bv1 else 0bv1))) != 0bv32 then 1bv1 else 0bv1) != 0bv1;
requires {:procedure_wide_invariant} {:do_not_predicate} {:sourceloc_num 2} (if (_WRITE_HAS_OCCURRED_$$A ==> BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), 0bv64) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV64_SLE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), 8191bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_UREM(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 8192bv32)), BV64_MUL(32bv64, BV32_ZEXT64(group_id_y))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_y)), 31bv64), BV32_ZEXT64(BV32_UREM(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 8192bv32))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_z), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1))) != 0bv32) then 1bv1 else 0bv1) != 0bv1;
requires {:procedure_wide_invariant} {:do_not_predicate} {:sourceloc_num 3} (if (_READ_HAS_OCCURRED_$$B ==> BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_OR(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)), BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), 1bv64)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), 1bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), BV64_MUL(4bv64, BV64_SDIV(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64))), 30bv64), BV64_ADD(BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV64_SUB(0bv64, BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64)), BV64_MUL(32bv64, BV32_ZEXT64(group_id_y))), BV64_MUL(8192bv64, BV32_ZEXT64(local_id_y))), BV32_ZEXT64(BV32_MUL(8191bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 32bv64), 8192bv64), BV32_ZEXT64(local_id_y)), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(local_id_z)), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)))), 1bv64), 4bv64)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 3bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)), BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), 1bv64)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_SEXT64($n), BV64_ADD(BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 1bv64)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), 1bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), BV64_MUL(4bv64, BV64_SDIV(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64))), 30bv64), BV64_ADD(BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV64_SUB(0bv64, BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64)), BV64_MUL(32bv64, BV32_ZEXT64(group_id_y))), BV64_MUL(8192bv64, BV32_ZEXT64(local_id_y))), BV32_ZEXT64(BV32_MUL(8191bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 32bv64), 8192bv64), BV32_ZEXT64(local_id_y)), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_SREM(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 1bv64), 4bv64), BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(local_id_z)), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)))), 1bv64), 4bv64)) then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 1bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)), 4bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV64_MUL(32bv64, BV32_ZEXT64(group_id_y))), BV32_ZEXT64(local_id_x)), BV64_MUL(8192bv64, BV32_ZEXT64(local_id_y))), BV32_ZEXT64(BV32_MUL(8191bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n)))), BV32_ZEXT64(BV32_MUL(8191bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 32bv64), 8192bv64), 31bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 1bv64), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_z), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), 0bv64) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV64_SLE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), 8191bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 3bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 0bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_UREM(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 8192bv32)), BV64_MUL(32bv64, BV32_ZEXT64(group_id_y))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_y)), 31bv64), BV32_ZEXT64(BV32_UREM(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 8192bv32))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8191bv64), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_z), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), 0bv64) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV64_SLE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), 8191bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 3bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 0bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_UREM(BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 1bv32), 8192bv32)), BV64_MUL(32bv64, BV32_ZEXT64(group_id_y))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_y)), 31bv64), BV32_ZEXT64(BV32_UREM(BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 1bv32), 8192bv32))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 3bv64), 4bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_z), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), 0bv64) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV64_SLE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), 8191bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 3bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 0bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_UREM(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 8192bv32)), BV64_MUL(32bv64, BV32_ZEXT64(group_id_y))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_y)), 31bv64), BV32_ZEXT64(BV32_UREM(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 8192bv32))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_SUB(BV32_ZEXT64(local_id_z), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))), 3bv64), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(local_id_y), 1bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)), BV32_ZEXT64(local_id_y)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ULE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))), BV64_ADD(BV32_ZEXT64(local_id_y), 2bv64)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV32_SEXT64($n), BV32_ZEXT64(local_id_y)), BV64_ADD(BV64_ADD(BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(local_id_z)), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)))), 1bv64), 4bv64), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))), 1bv64)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV64_ADD(BV32_ZEXT64(local_id_y), 1bv64), BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_y), BV32_ZEXT64(local_id_z)), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)))), 1bv64), 4bv64), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))) then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(local_id_y) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 3bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_x), BV32_ZEXT64(local_id_z)), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n)))), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)))), 1bv64), 4bv64), 1bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 1bv32) == $n then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_SUB(BV64_ADD(BV64_ADD(BV32_SEXT64(BV32_MUL(8191bv32, $n)), BV64_MUL(32bv64, BV32_ZEXT64(group_id_y))), BV64_MUL(8192bv64, BV32_ZEXT64(local_id_y))), 8159bv64), 8192bv64), 31bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_ADD(BV32_SEXT64(BV32_SUB(0bv32, $n)), BV32_ZEXT64(local_id_y)), 2bv64), 4bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_z), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(local_id_z) == 1bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_y)), BV64_MUL(8192bv64, BV32_ZEXT64(local_id_y))), BV32_ZEXT64(BV32_MUL(8191bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 31bv64), 8192bv64), 31bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)), 4bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 1bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) == $n then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_y)), BV64_MUL(8192bv64, BV32_ZEXT64(local_id_y))), BV32_ZEXT64(BV32_MUL(8191bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 31bv64), 8192bv64), 31bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_ADD(BV32_SEXT64(BV32_SUB(0bv32, $n)), BV32_ZEXT64(local_id_z)), 2bv64), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV32_ZEXT64(local_id_x), 2bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_y) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 2bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)), BV32_ZEXT64(local_id_x)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SGE(BV32_ZEXT64(local_id_x), BV64_ADD(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV32_ZEXT64(local_id_x), BV32_ZEXT64(local_id_z)), BV32_ZEXT64(BV32_MUL(3bv32, BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n)))), 3bv64), 4bv64), 1bv64)) then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_z) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 3bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_y)), BV64_MUL(8192bv64, BV32_ZEXT64(local_id_y))), BV32_ZEXT64(BV32_MUL(8191bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 31bv64), 8192bv64), 31bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 3bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) == $n then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SLE(BV64_SREM(BV64_ADD(BV64_ADD(BV64_ADD(BV64_MUL(32bv64, BV32_ZEXT64(group_id_y)), BV64_MUL(8192bv64, BV32_ZEXT64(local_id_y))), BV32_ZEXT64(BV32_MUL(8191bv32, BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n)))), 31bv64), 8192bv64), 31bv64) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_y), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n))), 4bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_ADD(BV32_SEXT64(BV32_SUB(0bv32, $n)), BV32_ZEXT64(local_id_z)), 2bv64), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(local_id_y) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_z) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 3bv32) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UGE($n, BV32_ADD(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n), 2bv32)) then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_SUB(BV32_ZEXT64(local_id_x), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 32bv64) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_SUB(BV64_MUL(18446744073709551584bv64, BV32_ZEXT64(group_id_x)), BV32_ZEXT64(local_id_x)), BV32_ZEXT64(BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n))), 8192bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_SGE($n, 4bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_y) == 2bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_z) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n) == 2bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n) == 1bv32 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_SGE($n, 4bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 2bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_y) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_z) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 2bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n) == 1bv32 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_y) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_z) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n) == 1bv32 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_SGE($n, 4bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_y) == 2bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n) == 2bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) == $n then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_ADD(BV32_SEXT64(BV32_SUB(0bv32, $n)), BV32_ZEXT64(local_id_z)), 2bv64), 4bv64) == 0bv64 then 1bv1 else 0bv1)))), BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV32_AND(BV1_ZEXT32((if BV32_SGE($n, 4bv32) then 1bv1 else 0bv1)), BV1_ZEXT32((if BV32_ZEXT64(group_id_x) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(group_id_y) == 0bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_x) == 2bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ZEXT64(local_id_y) == 1bv64 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n), $n) == 2bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_UREM(BV32_UDIV(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), $n) == 1bv32 then 1bv1 else 0bv1))), BV1_ZEXT32((if BV32_ADD(BV32_UREM(BV32_UDIV(BV32_MUL(8bv32, _WATCHED_OFFSET), 8bv32), $n), 1bv32) == $n then 1bv1 else 0bv1))), BV1_ZEXT32((if BV64_SREM(BV64_ADD(BV64_ADD(BV32_SEXT64(BV32_SUB(0bv32, $n)), BV32_ZEXT64(local_id_z)), 2bv64), 4bv64) == 0bv64 then 1bv1 else 0bv1)))) != 0bv32) then 1bv1 else 0bv1) != 0bv1;
{
  var $c1.0:bv64;
  var $c2.0:bv64;
  var $c3.0:bv64;
  var $cond:bv64;
  var $c5.0:bv64;
  var $cond65:bv64;
  var $cond84:bv64;
  var $c6.0:bv64;
  var $cond97:bv64;
  var v21:bv64;
  var v25:bv64;
  var v23:bv64;
  var v22:bv64;
  var v24:bv64;
  var v12:bool;
  var v11:bool;
  var v13:bool;
  var v14:bool;
  var v15:bool;
  var v19:bv64;
  var v16:bv64;
  var v17:bv64;
  var v18:bv64;
  var v20:bv64;
  var v10:bool;
  var v9:bool;
  var v2:bv64;
  var v1:bv64;
  var v3:bv64;
  var v0:bv64;
  var v4:bv64;
  var v6:bool;
  var v7:bool;
  var v5:bool;
  var v8:bool;
$entry:
  assert {:block_sourceloc} {:sourceloc_num 4} true;
  v0 := BV32_ZEXT64(group_id_x);
  v1 := BV32_ZEXT64(group_id_y);
  v2 := BV32_ZEXT64(local_id_x);
  v3 := BV32_ZEXT64(local_id_y);
  v4 := BV32_ZEXT64(local_id_z);
  $c1.0 := BV64_MUL(32bv64, v0);
  goto $for.cond;
$for.cond:
  assert {:block_sourceloc} {:sourceloc_num 5} true;
  v5 := BV64_SLT($c1.0, BV32_SEXT64(BV32_SUB($n, 1bv32)));
  goto $truebb, $falsebb;
$for.body:
  assert {:block_sourceloc} {:sourceloc_num 6} true;
  v6 := BV64_SGE(BV32_SEXT64($n), BV64_ADD(BV64_ADD(v2, $c1.0), 2bv64));
  goto $truebb0, $falsebb0;
$land.lhs.true:
  assert {:block_sourceloc} {:sourceloc_num 7} true;
  v7 := BV64_SGE(BV64_ADD(v2, $c1.0), 1bv64);
  goto $truebb1, $falsebb1;
$if.then:
  assert {:block_sourceloc} {:sourceloc_num 8} true;
  $c2.0 := BV64_MUL(32bv64, v1);
  goto $for.cond.30;
$for.cond.30:
  assert {:block_sourceloc} {:sourceloc_num 9} true;
  v8 := BV64_SLT($c2.0, BV32_SEXT64(BV32_SUB($n, 1bv32)));
  goto $truebb2, $falsebb2;
$for.body.35:
  assert {:block_sourceloc} {:sourceloc_num 10} true;
  $c3.0 := 0bv64;
  goto $for.cond.36;
$for.cond.36:
  assert {:block_sourceloc} {:sourceloc_num 11} true;
  v9 := BV64_SLT($c3.0, BV32_SEXT64(BV32_SUB($n, 1bv32)));
  goto $truebb3, $falsebb3;
$for.body.41:
  assert {:block_sourceloc} {:sourceloc_num 12} true;
  v10 := BV64_SGT(v3, BV64_ADD(BV64_SUB(BV64_SREM(BV64_ADD(BV64_ADD(v3, $c2.0), 3bv64), 4bv64), $c2.0), 1bv64));
  goto $truebb4, $falsebb4;
$cond.true:
  assert {:block_sourceloc} {:sourceloc_num 13} true;
  $cond := v3;
  goto $cond.end;
$cond.false:
  assert {:block_sourceloc} {:sourceloc_num 14} true;
  $cond := BV64_ADD(BV64_SUB(BV64_SREM(BV64_ADD(BV64_ADD(v3, $c2.0), 3bv64), 4bv64), $c2.0), 1bv64);
  goto $cond.end;
$cond.end:
  assert {:block_sourceloc} {:sourceloc_num 15} true;
  $c5.0 := $cond;
  goto $for.cond.53;
$for.cond.53:
  assert {:block_sourceloc} {:sourceloc_num 16} true;
  v11 := BV64_SLT(31bv64, BV64_SUB(BV64_SUB(BV32_SEXT64($n), $c2.0), 2bv64));
  goto $truebb5, $falsebb5;
$cond.true.59:
  assert {:block_sourceloc} {:sourceloc_num 17} true;
  $cond65 := 31bv64;
  goto $cond.end.64;
$cond.false.60:
  assert {:block_sourceloc} {:sourceloc_num 18} true;
  $cond65 := BV64_SUB(BV64_SUB(BV32_SEXT64($n), $c2.0), 2bv64);
  goto $cond.end.64;
$cond.end.64:
  assert {:block_sourceloc} {:sourceloc_num 19} true;
  v12 := BV64_SLE($c5.0, $cond65);
  goto $truebb6, $falsebb6;
$for.body.68:
  assert {:block_sourceloc} {:sourceloc_num 20} true;
  v13 := BV64_SGT(v4, BV64_ADD(BV64_SUB(BV64_SREM(BV64_ADD(BV64_ADD(v4, $c3.0), 3bv64), 4bv64), $c3.0), 1bv64));
  goto $truebb7, $falsebb7;
$cond.true.76:
  assert {:block_sourceloc} {:sourceloc_num 21} true;
  $cond84 := v4;
  goto $cond.end.83;
$cond.false.77:
  assert {:block_sourceloc} {:sourceloc_num 22} true;
  $cond84 := BV64_ADD(BV64_SUB(BV64_SREM(BV64_ADD(BV64_ADD(v4, $c3.0), 3bv64), 4bv64), $c3.0), 1bv64);
  goto $cond.end.83;
$cond.end.83:
  assert {:block_sourceloc} {:sourceloc_num 23} true;
  $c6.0 := $cond84;
  goto $for.cond.85;
$for.cond.85:
  assert {:block_sourceloc} {:sourceloc_num 24} true;
  v14 := BV64_SLT(31bv64, BV64_SUB(BV64_SUB(BV32_SEXT64($n), $c3.0), 2bv64));
  goto $truebb8, $falsebb8;
$cond.true.91:
  assert {:block_sourceloc} {:sourceloc_num 25} true;
  $cond97 := 31bv64;
  goto $cond.end.96;
$cond.false.92:
  assert {:block_sourceloc} {:sourceloc_num 26} true;
  $cond97 := BV64_SUB(BV64_SUB(BV32_SEXT64($n), $c3.0), 2bv64);
  goto $cond.end.96;
$cond.end.96:
  assert {:block_sourceloc} {:sourceloc_num 27} true;
  v15 := BV64_SLE($c6.0, $cond97);
  goto $truebb9, $falsebb9;
$for.body.100:
  assert {:block_sourceloc} {:sourceloc_num 28} true;
  assert {:sourceloc} {:sourceloc_num 29} true;
  v16 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(BV64_ADD(v2, $c1.0), 1bv64), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]];
  assert {:sourceloc} {:sourceloc_num 30} true;
  v17 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]];
  assert {:sourceloc} {:sourceloc_num 31} true;
  v18 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_SUB(BV64_ADD(v2, $c1.0), 1bv64), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]];
  assert {:sourceloc} {:sourceloc_num 32} true;
  v19 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_ADD(BV64_ADD($c2.0, $c5.0), 1bv64)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]];
  assert {:sourceloc} {:sourceloc_num 33} true;
  v20 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]];
  assert {:sourceloc} {:sourceloc_num 34} true;
  v21 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_SUB(BV64_ADD($c2.0, $c5.0), 1bv64)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]];
  assert {:sourceloc} {:sourceloc_num 35} true;
  v22 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_ADD(BV64_ADD($c3.0, $c6.0), 1bv64))[32:0]];
  assert {:sourceloc} {:sourceloc_num 36} true;
  v23 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]];
  assert {:sourceloc} {:sourceloc_num 37} true;
  v24 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_SUB(BV64_ADD($c3.0, $c6.0), 1bv64))[32:0]];
  assert {:sourceloc} {:sourceloc_num 38} true;
  v25 := $$B[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]];
  assert {:sourceloc} {:sourceloc_num 39} true;
  $$A[BV64_ADD(BV64_MUL(BV64_ADD(BV64_MUL(BV64_ADD(v2, $c1.0), BV32_SEXT64($n)), BV64_ADD($c2.0, $c5.0)), BV32_SEXT64($n)), BV64_ADD($c3.0, $c6.0))[32:0]] := FADD64(FADD64(FMUL64(4593671619917905920bv64, FADD64(FADD64(FMUL64(13835058055282163712bv64, v23), v22), v24)), FADD64(FMUL64(4593671619917905920bv64, FADD64(FADD64(FMUL64(13835058055282163712bv64, v17), v16), v18)), FMUL64(4593671619917905920bv64, FADD64(FADD64(FMUL64(13835058055282163712bv64, v20), v19), v21)))), v25);
  goto $for.inc;
$for.inc:
  assert {:block_sourceloc} {:sourceloc_num 40} true;
  $c6.0 := BV64_ADD($c6.0, 4bv64);
  goto $for.cond.85;
$for.end:
  assert {:block_sourceloc} {:sourceloc_num 41} true;
  goto $for.inc.237;
$for.inc.237:
  assert {:block_sourceloc} {:sourceloc_num 42} true;
  $c5.0 := BV64_ADD($c5.0, 4bv64);
  goto $for.cond.53;
$for.end.239:
  assert {:block_sourceloc} {:sourceloc_num 43} true;
  goto $for.inc.240;
$for.inc.240:
  assert {:block_sourceloc} {:sourceloc_num 44} true;
  $c3.0 := BV64_ADD($c3.0, 32bv64);
  goto $for.cond.36;
$for.end.242:
  assert {:block_sourceloc} {:sourceloc_num 45} true;
  goto $for.inc.243;
$for.inc.243:
  assert {:block_sourceloc} {:sourceloc_num 46} true;
  $c2.0 := BV64_ADD($c2.0, 8192bv64);
  goto $for.cond.30;
$for.end.245:
  assert {:block_sourceloc} {:sourceloc_num 47} true;
  goto $if.end;
$if.end:
  assert {:block_sourceloc} {:sourceloc_num 48} true;
  goto $for.inc.246;
$for.inc.246:
  assert {:block_sourceloc} {:sourceloc_num 49} true;
  $c1.0 := BV64_ADD($c1.0, 8192bv64);
  goto $for.cond;
$for.end.248:
  assert {:block_sourceloc} {:sourceloc_num 50} true;
  return;
$truebb:
  assume {:partition} v5;
  assert {:block_sourceloc} {:sourceloc_num 51} true;
  goto $for.body;
$falsebb:
  assume {:partition} !v5;
  assert {:block_sourceloc} {:sourceloc_num 52} true;
  goto $for.end.248;
$truebb0:
  assume {:partition} v6;
  assert {:block_sourceloc} {:sourceloc_num 53} true;
  goto $land.lhs.true;
$falsebb0:
  assume {:partition} !v6;
  assert {:block_sourceloc} {:sourceloc_num 54} true;
  goto $if.end;
$truebb1:
  assume {:partition} v7;
  assert {:block_sourceloc} {:sourceloc_num 55} true;
  goto $if.then;
$falsebb1:
  assume {:partition} !v7;
  assert {:block_sourceloc} {:sourceloc_num 56} true;
  goto $if.end;
$truebb2:
  assume {:partition} v8;
  assert {:block_sourceloc} {:sourceloc_num 57} true;
  goto $for.body.35;
$falsebb2:
  assume {:partition} !v8;
  assert {:block_sourceloc} {:sourceloc_num 58} true;
  goto $for.end.245;
$truebb3:
  assume {:partition} v9;
  assert {:block_sourceloc} {:sourceloc_num 59} true;
  goto $for.body.41;
$falsebb3:
  assume {:partition} !v9;
  assert {:block_sourceloc} {:sourceloc_num 60} true;
  goto $for.end.242;
$truebb4:
  assume {:partition} v10;
  assert {:block_sourceloc} {:sourceloc_num 61} true;
  goto $cond.true;
$falsebb4:
  assume {:partition} !v10;
  assert {:block_sourceloc} {:sourceloc_num 62} true;
  goto $cond.false;
$truebb5:
  assume {:partition} v11;
  assert {:block_sourceloc} {:sourceloc_num 63} true;
  goto $cond.true.59;
$falsebb5:
  assume {:partition} !v11;
  assert {:block_sourceloc} {:sourceloc_num 64} true;
  goto $cond.false.60;
$truebb6:
  assume {:partition} v12;
  assert {:block_sourceloc} {:sourceloc_num 65} true;
  goto $for.body.68;
$falsebb6:
  assume {:partition} !v12;
  assert {:block_sourceloc} {:sourceloc_num 66} true;
  goto $for.end.239;
$truebb7:
  assume {:partition} v13;
  assert {:block_sourceloc} {:sourceloc_num 67} true;
  goto $cond.true.76;
$falsebb7:
  assume {:partition} !v13;
  assert {:block_sourceloc} {:sourceloc_num 68} true;
  goto $cond.false.77;
$truebb8:
  assume {:partition} v14;
  assert {:block_sourceloc} {:sourceloc_num 69} true;
  goto $cond.true.91;
$falsebb8:
  assume {:partition} !v14;
  assert {:block_sourceloc} {:sourceloc_num 70} true;
  goto $cond.false.92;
$truebb9:
  assume {:partition} v15;
  assert {:block_sourceloc} {:sourceloc_num 71} true;
  goto $for.body.100;
$falsebb9:
  assume {:partition} !v15;
  assert {:block_sourceloc} {:sourceloc_num 72} true;
  goto $for.end;
}
axiom (if group_size_x == 32bv32 then 1bv1 else 0bv1) != 0bv1;
axiom (if group_size_y == 4bv32 then 1bv1 else 0bv1) != 0bv1;
axiom (if group_size_z == 4bv32 then 1bv1 else 0bv1) != 0bv1;
axiom (if num_groups_x == 16bv32 then 1bv1 else 0bv1) != 0bv1;
axiom (if num_groups_y == 16bv32 then 1bv1 else 0bv1) != 0bv1;
axiom (if num_groups_z == 1bv32 then 1bv1 else 0bv1) != 0bv1;
axiom (if global_offset_x == 0bv32 then 1bv1 else 0bv1) != 0bv1;
axiom (if global_offset_y == 0bv32 then 1bv1 else 0bv1) != 0bv1;
axiom (if global_offset_z == 0bv32 then 1bv1 else 0bv1) != 0bv1;
